This repository was forked from https://github.com/spro/char-rnn.pytorch and some of the code was modified to fit Datahub cells. The code in this repository supplements my final project for COGS 181. 
Abstract: Character Recurrent Neural Networks (Char-RNNs) are very powerful in the context of text generation, or modeling and generating sequential data. This project explores the effectiveness of  Char-RNN implementation in the style and structure of datasets such as Tiny Shakespeare or an Agatha Christie collection. I investigate the impact and results of fine tuning the model on different hyperparameters, such as model types, RNN size, layers, learning rate, and shuffling. Through multiple trials and analysis criteria, I identify the optimal hyperparameters to generate coherent text. The findings demonstrate the potential that RNNs has in the field of text generation and the implications of thus on using these models for varied word-related industries and research.
